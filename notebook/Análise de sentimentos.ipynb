{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521ab227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Obtaining dependency information for xlsxwriter from https://files.pythonhosted.org/packages/3a/0c/3662f4a66880196a590b202f0db82d919dd2f89e99a27fadef91c4a33d41/xlsxwriter-3.2.9-py3-none-any.whl.metadata\n",
      "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
      "   ---------------------------------------- 0.0/175.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/175.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/175.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/175.3 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 41.0/175.3 kB 279.3 kB/s eta 0:00:01\n",
      "   -------------------- ------------------ 92.2/175.3 kB 581.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 175.3/175.3 kB 878.1 kB/s eta 0:00:00\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093f0eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DownloadError' from 'nltk' (C:\\Users\\Natasha\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadError\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DownloadError' from 'nltk' (C:\\Users\\Natasha\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import DownloadError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae83b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ ESTRAT√âGIA DEFINITIVA: 400 CLASSIFICA√á√ïES MANUAIS\n",
      "======================================================================\n",
      "üìä Analisando dataset para selecionar amostra estrat√©gica...\n",
      "Coment√°rios v√°lidos: 40,950\n",
      "\n",
      "üîç Selecionando amostra estrat√©gica de 400 coment√°rios...\n",
      "\n",
      "1. Coletando NEGATIVOS √ìBVIOS...\n",
      "   Negativos coletados: 100\n",
      "\n",
      "2. Coletando POSITIVOS √ìBVIOS...\n",
      "   Positivos coletados: 100\n",
      "\n",
      "3. Coletando NEUTROS CLAROS...\n",
      "   Neutros coletados: 50\n",
      "\n",
      "4. Coletando CASOS DIF√çCEIS...\n",
      "   Casos dif√≠ceis coletados: 150\n",
      "\n",
      "üìä AMOSTRA FINAL SELECIONADA: 391 coment√°rios\n",
      "\n",
      "üíæ Criando arquivo para classifica√ß√£o manual...\n",
      "‚úÖ Arquivo criado: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\classificacao_manual_400.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---  CLASSIFICA√á√ÉO MANUAL ESTRAT√âGICA ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéØ 400 CLASSIFICA√á√ïES MANUAIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- PASSO 1: ANALISAR O DATASET PARA ESCOLHER OS 400 MELHORES ---\n",
    "print(\"üìä Analisando dataset para selecionar amostra estrat√©gica...\")\n",
    "\n",
    "# Carregar dataset\n",
    "df = pd.read_excel(r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\olist_avaliacoes.xlsx')\n",
    "\n",
    "# Filtrar apenas coment√°rios v√°lidos\n",
    "df = df[df['Msg_coment√°rio'].notna()]\n",
    "df['Msg_coment√°rio'] = df['Msg_coment√°rio'].astype(str).str.strip()\n",
    "df = df[df['Msg_coment√°rio'] != '']\n",
    "\n",
    "print(f\"Coment√°rios v√°lidos: {len(df):,}\")\n",
    "\n",
    "# --- PASSO 2: ESTRAT√âGIA DE SELE√á√ÉO INTELIGENTE ---\n",
    "print(\"\\nüîç Selecionando amostra estrat√©gica de 400 coment√°rios...\")\n",
    "\n",
    "amostra_estrat√©gica = []\n",
    "\n",
    "# ESTRAT√âGIA: Pegar exemplos de cada tipo de padr√£o\n",
    "\n",
    "# 1. NEGATIVOS √ìBVIOS (100 exemplos) - Prioridade M√ÅXIMA\n",
    "print(\"\\n1. Coletando NEGATIVOS √ìBVIOS...\")\n",
    "padroes_negativos = [\n",
    "    'n√£o gost', 'p√©ssim', 'ruim', 'horr√≠vel', 'decepcion', \n",
    "    'defeito', 'quebrado', 'n√£o funciona', 'n√£o recomendo',\n",
    "    'atrasado', 'demorou', 'lento', 'caro demais', 'perda de dinheiro'\n",
    "]\n",
    "\n",
    "negativos_coletados = 0\n",
    "for padrao in padroes_negativos:\n",
    "    mask = df['Msg_coment√°rio'].str.contains(padrao, case=False, na=False)\n",
    "    exemplos = df[mask].sample(min(15, sum(mask)), random_state=42)\n",
    "    \n",
    "    for _, row in exemplos.iterrows():\n",
    "        if negativos_coletados < 100:\n",
    "            amostra_estrat√©gica.append({\n",
    "                'Comentario': row['Msg_coment√°rio'],\n",
    "                'Tipo_Coleta': 'NEGATIVO_OBVIO',\n",
    "                'Classificacao_Sugerida': 'NEGATIVO',\n",
    "                'Classificacao_Manual': ''\n",
    "            })\n",
    "            negativos_coletados += 1\n",
    "\n",
    "print(f\"   Negativos coletados: {negativos_coletados}\")\n",
    "\n",
    "# 2. POSITIVOS √ìBVIOS (100 exemplos)\n",
    "print(\"\\n2. Coletando POSITIVOS √ìBVIOS...\")\n",
    "padroes_positivos = [\n",
    "    'excelente', 'perfeito', 'adorei', 'recomendo', '√≥timo',\n",
    "    'maravilhoso', 'superou', 'gostei muito', 'valeu a pena',\n",
    "    'r√°pida entrega', 'antes do prazo', 'qualidade excelente'\n",
    "]\n",
    "\n",
    "positivos_coletados = 0\n",
    "for padrao in padroes_positivos:\n",
    "    mask = df['Msg_coment√°rio'].str.contains(padrao, case=False, na=False)\n",
    "    exemplos = df[mask].sample(min(15, sum(mask)), random_state=42)\n",
    "    \n",
    "    for _, row in exemplos.iterrows():\n",
    "        # Verificar se n√£o tem nega√ß√£o antes\n",
    "        texto = row['Msg_coment√°rio'].lower()\n",
    "        pos = texto.find(padrao)\n",
    "        if pos > 0:\n",
    "            texto_antes = texto[:pos]\n",
    "            if any(neg in texto_antes for neg in ['n√£o', 'nem', 'mas', 'por√©m']):\n",
    "                continue  # Pular se tem nega√ß√£o\n",
    "        \n",
    "        if positivos_coletados < 100:\n",
    "            amostra_estrat√©gica.append({\n",
    "                'Comentario': row['Msg_coment√°rio'],\n",
    "                'Tipo_Coleta': 'POSITIVO_OBVIO',\n",
    "                'Classificacao_Sugerida': 'POSITIVO',\n",
    "                'Classificacao_Manual': ''\n",
    "            })\n",
    "            positivos_coletados += 1\n",
    "\n",
    "print(f\"   Positivos coletados: {positivos_coletados}\")\n",
    "\n",
    "# 3. NEUTROS CLAROS (50 exemplos) - textos curtos factuais\n",
    "print(\"\\n3. Coletando NEUTROS CLAROS...\")\n",
    "neutros_coletados = 0\n",
    "for _, row in df.iterrows():\n",
    "    texto = str(row['Msg_coment√°rio'])\n",
    "    palavras = texto.split()\n",
    "    \n",
    "    # Textos curtos com palavras factuais\n",
    "    if len(palavras) <= 6:\n",
    "        palavras_factuais = ['recebi', 'chegou', 'entregue', 'produto', 'ok', 'certo']\n",
    "        if any(pal in texto.lower() for pal in palavras_factuais):\n",
    "            if neutros_coletados < 50:\n",
    "                amostra_estrat√©gica.append({\n",
    "                    'Comentario': texto,\n",
    "                    'Tipo_Coleta': 'NEUTRO_OBVIO',\n",
    "                    'Classificacao_Sugerida': 'NEUTRO',\n",
    "                    'Classificacao_Manual': ''\n",
    "                })\n",
    "                neutros_coletados += 1\n",
    "    \n",
    "    if neutros_coletados >= 50:\n",
    "        break\n",
    "\n",
    "print(f\"   Neutros coletados: {neutros_coletados}\")\n",
    "\n",
    "# 4. CASOS DIF√çCEIS/AMB√çGUOS (150 exemplos) - onde o modelo erra\n",
    "print(\"\\n4. Coletando CASOS DIF√çCEIS...\")\n",
    "\n",
    "# Primeiro, usar resultados anteriores para pegar onde o modelo errou\n",
    "try:\n",
    "    resultados_anteriores = pd.read_excel(\n",
    "        r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\resultados_corrigidos_finais.xlsx',\n",
    "        sheet_name='Apenas_Comentarios_Validos'\n",
    "    )\n",
    "    \n",
    "    # Pegar casos onde confian√ßa √© baixa ou classifica√ß√£o √© suspeita\n",
    "    casos_dificeis = resultados_anteriores[\n",
    "        (resultados_anteriores['Confianca'] < 0.6) |\n",
    "        ((resultados_anteriores['Sentimento'] == 'POSITIVO') & \n",
    "         resultados_anteriores['Msg_coment√°rio'].str.contains('n√£o|problema|defeito', case=False, na=False)) |\n",
    "        ((resultados_anteriores['Sentimento'] == 'NEGATIVO') & \n",
    "         resultados_anteriores['Msg_coment√°rio'].str.contains('excelente|perfeito|adorei', case=False, na=False))\n",
    "    ].sample(min(150, len(resultados_anteriores)), random_state=42)\n",
    "    \n",
    "    for _, row in casos_dificeis.iterrows():\n",
    "        amostra_estrat√©gica.append({\n",
    "            'Comentario': row['Msg_coment√°rio'],\n",
    "            'Tipo_Coleta': 'CASO_DIFICIL',\n",
    "            'Classificacao_Sugerida': '',  # N√£o sugerir - voc√™ decide\n",
    "            'Classificacao_Manual': ''\n",
    "        })\n",
    "    \n",
    "    print(f\"   Casos dif√≠ceis coletados: {len(casos_dificeis)}\")\n",
    "    \n",
    "except:\n",
    "    # Se n√£o tiver resultados anteriores, pegar aleat√≥rio\n",
    "    casos_aleatorios = df.sample(150, random_state=42)\n",
    "    for _, row in casos_aleatorios.iterrows():\n",
    "        amostra_estrat√©gica.append({\n",
    "            'Comentario': row['Msg_coment√°rio'],\n",
    "            'Tipo_Coleta': 'ALEATORIO',\n",
    "            'Classificacao_Sugerida': '',\n",
    "            'Classificacao_Manual': ''\n",
    "        })\n",
    "    print(f\"   Casos aleat√≥rios coletados: 150\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df_amostra = pd.DataFrame(amostra_estrat√©gica)\n",
    "df_amostra = df_amostra.drop_duplicates(subset=['Comentario'])\n",
    "\n",
    "print(f\"\\nüìä AMOSTRA FINAL SELECIONADA: {len(df_amostra)} coment√°rios\")\n",
    "\n",
    "# --- PASSO 3: CRIAR ARQUIVO PARA CLASSIFICA√á√ÉO MANUAL ---\n",
    "print(\"\\nüíæ Criando arquivo para classifica√ß√£o manual...\")\n",
    "\n",
    "caminho_classificacao = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\classificacao_manual_400.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(caminho_classificacao, engine='xlsxwriter') as writer:\n",
    "    # Aba principal\n",
    "    df_amostra.to_excel(writer, sheet_name='Classificar', index=False)\n",
    "    \n",
    "    # Aba de instru√ß√µes detalhadas\n",
    "    instrucoes = pd.DataFrame({\n",
    "        'INSTRU√á√ïES DETALHADAS': [\n",
    "            '='*70,\n",
    "            'üéØ CLASSIFIQUE 400 COMENT√ÅRIOS MANUALMENTE',\n",
    "            '='*70,\n",
    "            '',\n",
    "            'üìã REGRAS CLARAS PARA CLASSIFICA√á√ÉO:',\n",
    "            '',\n",
    "            'üî¥ NEGATIVO (cliente INSATISFEITO):',\n",
    "            '   ‚Ä¢ \"n√£o gostei\", \"p√©ssimo\", \"ruim\", \"horr√≠vel\"',\n",
    "            '   ‚Ä¢ \"n√£o recomendo\", \"n√£o indico\"',\n",
    "            '   ‚Ä¢ \"defeito\", \"quebrado\", \"n√£o funciona\"',\n",
    "            '   ‚Ä¢ \"atrasou\", \"demorou muito\", \"caro demais\"',\n",
    "            '   ‚Ä¢ Reclama√ß√µes, problemas, insatisfa√ß√£o',\n",
    "            '',\n",
    "            'üü¢ POSITIVO (cliente SATISFEITO):',\n",
    "            '   ‚Ä¢ \"excelente\", \"perfeito\", \"√≥timo\", \"adorei\"',\n",
    "            '   ‚Ä¢ \"recomendo\", \"superou expectativas\"',\n",
    "            '   ‚Ä¢ Elogios, satisfa√ß√£o, vai comprar de novo',\n",
    "            '   ‚Ä¢ ‚ö†Ô∏è CUIDADO: \"excelente MAS...\" pode ser negativo!',\n",
    "            '',\n",
    "            '‚ö™ NEUTRO (apenas INFORMATIVO):',\n",
    "            '   ‚Ä¢ \"recebi o produto\", \"chegou hoje\"',\n",
    "            '   ‚Ä¢ \"tudo certo\", \"conforme pedido\"',\n",
    "            '   ‚Ä¢ Fatos sem emo√ß√£o, apenas informa√ß√£o',\n",
    "            '   ‚Ä¢ Textos curtos (at√© 6 palavras) factuais',\n",
    "            '',\n",
    "            'üéØ EXEMPLOS PR√ÅTICOS:',\n",
    "            '1. \"Produto veio com defeito\" ‚Üí NEGATIVO',\n",
    "            '2. \"Adorei, recomendo!\" ‚Üí POSITIVO',\n",
    "            '3. \"Recebi hoje\" ‚Üí NEUTRO',\n",
    "            '4. \"Excelente mas demorou\" ‚Üí NEGATIVO (tem \"mas\")',\n",
    "            '5. \"N√£o gostei, qualidade ruim\" ‚Üí NEGATIVO',\n",
    "            '6. \"Chegou antes do prazo\" ‚Üí POSITIVO',\n",
    "            '',\n",
    "            'üìù COMO CLASSIFICAR:',\n",
    "            '1. Leia o coment√°rio',\n",
    "            '2. Identifique a EMO√á√ÉO do cliente',\n",
    "            '3. Use as regras acima',\n",
    "            '4. Preencha \"Classificacao_Manual\" com:',\n",
    "            '   - POSITIVO (üü¢)',\n",
    "            '   - NEGATIVO (üî¥)',\n",
    "            '   - NEUTRO (‚ö™)',\n",
    "            '',\n",
    "            '‚è∞ TEMPO ESTIMADO: 60-90 minutos',\n",
    "            'üí° DICA: Classifique em 2 sess√µes de 30-45 min'\n",
    "        ]\n",
    "    })\n",
    "    instrucoes.to_excel(writer, sheet_name='Instrucoes', index=False)\n",
    "    \n",
    "    # Aba com exemplos j√° classificados\n",
    "    exemplos_classificados = pd.DataFrame({\n",
    "        'Comentario': [\n",
    "            'n√£o gostei do produto',\n",
    "            'excelente qualidade, recomendo',\n",
    "            'recebi o produto hoje',\n",
    "            'veio com defeito, n√£o funciona',\n",
    "            'chegou atrasado mas gostei',\n",
    "            'p√©ssimo, nunca mais compro',\n",
    "            'tudo certo com a entrega',\n",
    "            'produto bom pelo pre√ßo'\n",
    "        ],\n",
    "        'Classificacao_Correta': [\n",
    "            'NEGATIVO',\n",
    "            'POSITIVO',\n",
    "            'NEUTRO',\n",
    "            'NEGATIVO',\n",
    "            'POSITIVO',  # Termina positivo apesar do problema\n",
    "            'NEGATIVO',\n",
    "            'NEUTRO',\n",
    "            'POSITIVO'\n",
    "        ],\n",
    "        'Explicacao': [\n",
    "            'Claramente insatisfeito',\n",
    "            'Claramente satisfeito e recomenda',\n",
    "            'Apenas informativo, sem emo√ß√£o',\n",
    "            'Reclama√ß√£o de defeito',\n",
    "            'Problema mas ficou satisfeito no final',\n",
    "            'Muito insatisfeito',\n",
    "            'Apenas informativo',\n",
    "            'Satisfeito com custo-benef√≠cio'\n",
    "        ]\n",
    "    })\n",
    "    exemplos_classificados.to_excel(writer, sheet_name='Exemplos', index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo criado: {caminho_classificacao}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c9c7205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ü§ñ TREINANDO NOVO MODELO COM AS CLASSIFICA√á√ïES MANUAIS (400+)\n",
      "======================================================================\n",
      "‚úÖ Classifica√ß√µes v√°lidas encontradas: 391\n",
      "Total de amostras de treino (400 + antigas): 584\n",
      "‚úÖ Acur√°cia do novo modelo (Teste/Valida√ß√£o): 80.3%\n",
      "üíæ Modelo salvo em: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\modelo_400_classificacoes.pkl\n",
      "\n",
      "Total de linhas no dataset completo: 99224\n",
      "‚úÖ Resultados finais salvos: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\resultados_finais_400_treinados.xlsx\n",
      "\n",
      "======================================================================\n",
      "üìä ESTAT√çSTICAS FINAIS\n",
      "======================================================================\n",
      "Distribui√ß√£o dos 3 coment√°rios classificados:\n",
      "  NEGATIVO: 18,724 (45.7%)\n",
      "  POSITIVO: 18,295 (44.7%)\n",
      "  NEUTRO: 3,931 (9.6%)\n",
      "\n",
      "üé≠ Confian√ßa M√©dia das Classifica√ß√µes: 76.2%\n",
      "\n",
      "======================================================================\n",
      "üéâ PROCESSO CONCLU√çDO COM SUCESSO!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- C√ìDIGO DE EXECU√á√ÉO ---\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords # Importar nltk\n",
    "\n",
    "# Voc√™ pode precisar baixar as stopwords se for a primeira vez\n",
    "# import nltk\n",
    "# nltk.download('stopwords') \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ü§ñ TREINANDO NOVO MODELO COM AS CLASSIFICA√á√ïES MANUAIS (400+)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Carregar suas 400 classifica√ß√µes\n",
    "caminho_400 = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\classificacao_manual_400.xlsx'\n",
    "try:\n",
    "    df_classificado = pd.read_excel(\n",
    "        caminho_400,\n",
    "        sheet_name='Classificar'\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Arquivo de classifica√ß√£o manual n√£o encontrado em: {caminho_400}\")\n",
    "    # Voc√™ pode querer sair do script aqui\n",
    "    exit()\n",
    "\n",
    "df_classificado = df_classificado[df_classificado['Classificacao_Manual'].notna()]\n",
    "df_classificado['Classificacao_Manual'] = df_classificado['Classificacao_Manual'].str.strip().str.upper()\n",
    "\n",
    "print(f\"‚úÖ Classifica√ß√µes v√°lidas encontradas: {len(df_classificado)}\")\n",
    "\n",
    "# 2. Adicionar valida√ß√µes anteriores (se quiser)\n",
    "caminho_validacoes_antigas = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\validacao_manual_final.xlsx'\n",
    "try:\n",
    "    validacoes_anteriores = pd.read_excel(\n",
    "        caminho_validacoes_antigas,\n",
    "        sheet_name='Classificar'\n",
    "    )\n",
    "    validacoes_anteriores = validacoes_anteriores[validacoes_anteriores['Classificacao_Manual'].notna()]\n",
    "    \n",
    "    # Combinar\n",
    "    df_treino = pd.concat([\n",
    "        # Renomeia para 'Msg_coment√°rio' para combinar\n",
    "        df_classificado.rename(columns={'Comentario': 'Msg_coment√°rio'}), \n",
    "        validacoes_anteriores[['Msg_coment√°rio', 'Classificacao_Manual']]\n",
    "    ], ignore_index=True).drop_duplicates(subset=['Msg_coment√°rio']) # Remove duplicatas\n",
    "    \n",
    "    print(f\"Total de amostras de treino (400 + antigas): {len(df_treino)}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è N√£o foi poss√≠vel carregar valida√ß√µes anteriores. Usando apenas as 400.\")\n",
    "    df_treino = df_classificado.rename(columns={'Comentario': 'Msg_coment√°rio'})\n",
    "\n",
    "# 3. Pr√©-processamento (fun√ß√£o simples)\n",
    "def preprocessar_simples(textos):\n",
    "    processados = []\n",
    "    for texto in textos:\n",
    "        texto = str(texto).lower()\n",
    "        # Nota: O uso de \\\\s no re.sub est√° correto dentro de f-strings ou strings longas.\n",
    "        texto = re.sub(r'[^a-z√°√†√¢√£√©√™√≠√≥√¥√µ√∫√º√ß0-9\\s]', ' ', texto) \n",
    "        texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "        processados.append(texto)\n",
    "    return processados\n",
    "\n",
    "# 4. Treinar modelo\n",
    "X = preprocessar_simples(df_treino['Msg_coment√°rio'].values)\n",
    "y = df_treino['Classificacao_Manual'].values\n",
    "\n",
    "# TfidfVectorizer aprimorado\n",
    "try:\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "except:\n",
    "    stop_words = []\n",
    "    print(\"‚ö†Ô∏è Stopwords n√£o encontradas. Continuando sem.\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1500, # Aumentado para melhor representa√ß√£o\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=stop_words,\n",
    "    min_df=2,\n",
    "    max_df=0.9\n",
    ")\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y # Estratifica√ß√£o √© crucial para bases pequenas\n",
    ")\n",
    "\n",
    "model = SVC(\n",
    "    kernel='linear', \n",
    "    probability=True, \n",
    "    random_state=42, \n",
    "    class_weight='balanced',\n",
    "    C=1.0 # Par√¢metro de regulariza√ß√£o\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Avaliar\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Acur√°cia do novo modelo (Teste/Valida√ß√£o): {accuracy:.1%}\")\n",
    "\n",
    "# 6. Salvar modelo\n",
    "modelo_final = {\n",
    "    'model': model,\n",
    "    'vectorizer': vectorizer,\n",
    "    'acuracia': accuracy,\n",
    "    'tamanho_treino': len(df_treino),\n",
    "    'distribuicao_classes': df_treino['Classificacao_Manual'].value_counts().to_dict(),\n",
    "    'data_treinamento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "caminho_modelo_final = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\modelo_400_classificacoes.pkl'\n",
    "with open(caminho_modelo_final, 'wb') as f:\n",
    "    pickle.dump(modelo_final, f)\n",
    "\n",
    "print(f\"üíæ Modelo salvo em: {caminho_modelo_final}\")\n",
    "\n",
    "# 7. Aplicar a todo dataset\n",
    "caminho_dataset_completo = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\olist_avaliacoes.xlsx'\n",
    "try:\n",
    "    df_completo = pd.read_excel(caminho_dataset_completo)\n",
    "    print(f\"\\nTotal de linhas no dataset completo: {len(df_completo)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Dataset completo n√£o encontrado em: {caminho_dataset_completo}\")\n",
    "    exit()\n",
    "\n",
    "# Classificar em lote para efici√™ncia\n",
    "textos_completos = df_completo['Msg_coment√°rio'].fillna('').astype(str).values\n",
    "textos_proc_completos = preprocessar_simples(textos_completos)\n",
    "\n",
    "X_todo = vectorizer.transform(textos_proc_completos)\n",
    "predicoes = model.predict(X_todo)\n",
    "probabilidades = model.predict_proba(X_todo)\n",
    "confiancas = np.max(probabilidades, axis=1)\n",
    "\n",
    "# Adicionar ao DataFrame\n",
    "df_completo['Sentimento'] = predicoes\n",
    "df_completo['Confianca'] = confiancas\n",
    "\n",
    "# Ajustar os coment√°rios vazios/ausentes\n",
    "mask_vazios = (df_completo['Msg_coment√°rio'].isna()) | (df_completo['Msg_coment√°rio'].str.strip() == '')\n",
    "df_completo.loc[mask_vazios, 'Sentimento'] = 'NEUTRO_VAZIO'\n",
    "df_completo.loc[mask_vazios, 'Confianca'] = 1.0\n",
    "\n",
    "# 8. Salvar resultados\n",
    "caminho_final_resultados = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\resultados_finais_400_treinados.xlsx'\n",
    "df_completo.to_excel(caminho_final_resultados, index=False)\n",
    "\n",
    "print(f\"‚úÖ Resultados finais salvos: {caminho_final_resultados}\")\n",
    "\n",
    "# Estat√≠sticas Finais\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ESTAT√çSTICAS FINAIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Distribui√ß√£o dos coment√°rios v√°lidos (excluindo neutro vazio)\n",
    "distrib = df_completo[df_completo['Sentimento'] != 'NEUTRO_VAZIO']['Sentimento'].value_counts()\n",
    "print(f\"Distribui√ß√£o dos {len(distrib):,} coment√°rios classificados:\")\n",
    "total_classificado = distrib.sum()\n",
    "\n",
    "for cat, qtd in distrib.items():\n",
    "    perc = qtd / total_classificado * 100\n",
    "    print(f\"  {cat}: {qtd:,} ({perc:.1f}%)\")\n",
    "\n",
    "conf_media = df_completo[df_completo['Sentimento'] != 'NEUTRO_VAZIO']['Confianca'].mean()\n",
    "print(f\"\\nüé≠ Confian√ßa M√©dia das Classifica√ß√µes: {conf_media:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PROCESSO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"======================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad8d5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ü§ñ TREINANDO E APLICANDO MODELO H√çBRIDO (ML + REGRAS DEFINITIVAS)\n",
      "======================================================================\n",
      "Total de amostras de treino para ML: 584\n",
      "‚úÖ Acur√°cia do ML puro (Teste/Valida√ß√£o): 80.3%\n",
      "üíæ Modelo ML puro salvo em: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\modelo_400_classificacoes_hibrido.pkl\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è APLICANDO MODELO H√çBRIDO (ML + REGRAS) AO DATASET COMPLETO\n",
      "======================================================================\n",
      "‚úÖ Resultados H√çBRIDOS (ML corrigido) salvos: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\resultados_finais_HIBRIDOS.xlsx\n",
      "\n",
      "======================================================================\n",
      "üìä ESTAT√çSTICAS FINAIS DO MODELO H√çBRIDO\n",
      "======================================================================\n",
      "Distribui√ß√£o dos 40,950 coment√°rios classificados:\n",
      "  NEGATIVO: 18,778 (45.9%)\n",
      "  POSITIVO: 17,863 (43.6%)\n",
      "  NEUTRO: 4,309 (10.5%)\n",
      "\n",
      "‚öôÔ∏è Total de Corre√ß√µes por Regra (Override): 14,280 (34.9%)\n",
      "Metodo\n",
      "Regra_Elogio     7847\n",
      "Regra_Critica    2453\n",
      "Regra_Erro       2136\n",
      "Regra_Curto      1130\n",
      "Regra_Atraso      644\n",
      "Regra_Mas_Pos      43\n",
      "Regra_Mas          27\n",
      "\n",
      "üé≠ Confian√ßa M√©dia Final: 81.3%\n",
      "\n",
      "======================================================================\n",
      "üéâ PROCESSO H√çBRIDO CONCLU√çDO COM SUCESSO!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- C√ìDIGO DE EXECU√á√ÉO H√çBRIDO ---\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ü§ñ TREINANDO E APLICANDO MODELO H√çBRIDO (ML + REGRAS DEFINITIVAS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- FUN√á√ÉO DE REGRAS DEFINITIVAS (SEU C√ìDIGO) ---\n",
    "def classificar_manual_corretamente(texto, classe_ml, confianca_ml):\n",
    "    \"\"\"\n",
    "    REGRAS DEFINITIVAS para corre√ß√£o (OVERRIDE) do modelo ML\n",
    "    \"\"\"\n",
    "    texto_lower = str(texto).lower()\n",
    "    \n",
    "    # 1. ERROS CR√çTICOS (M√ÅXIMA PRIORIDADE)\n",
    "    # Se cliente diz explicitamente N√ÉO GOSTOU = SEMPRE NEGATIVO\n",
    "    if any(phrase in texto_lower for phrase in ['n√£o gost', 'n√£o recomendo', 'insatisfeit']):\n",
    "        return 'NEGATIVO', 'Regra_Critica', max(confianca_ml, 0.99)\n",
    "    \n",
    "    # Se tem problema/defeito = SEMPRE NEGATIVO\n",
    "    if any(word in texto_lower for word in ['defeito', 'quebrado', 'amassado', 'rasgado', 'n√£o funciona', 'problema']):\n",
    "        return 'NEGATIVO', 'Regra_Critica', max(confianca_ml, 0.99)\n",
    "    \n",
    "    # 2. PROBLEMAS NA LOG√çSTICA (Alta Prioridade)\n",
    "    # Se tem atraso/demorou = SEMPRE NEGATIVO\n",
    "    if 'demorou' in texto_lower or 'atraso' in texto_lower or 'atrasou' in texto_lower or 'atrasada' in texto_lower:\n",
    "        # Se for um problema, mas terminar positivamente (\"mas chegou bem\")\n",
    "        if 'mas' in texto_lower:\n",
    "            partes = texto_lower.split('mas')\n",
    "            if len(partes) > 1 and any(pos in partes[-1] for pos in ['bom', 'valeu', 'gostei', 'ok', 'recomendo']):\n",
    "                return 'POSITIVO', 'Regra_Mas', max(confianca_ml, 0.90)\n",
    "        return 'NEGATIVO', 'Regra_Atraso', max(confianca_ml, 0.95)\n",
    "    \n",
    "    # Se recebeu errado/faltando = SEMPRE NEGATIVO\n",
    "    if any(phrase in texto_lower for phrase in ['veio errado', 'faltando', 'n√£o recebi', 'diferente do']):\n",
    "        return 'NEGATIVO', 'Regra_Erro', max(confianca_ml, 0.95)\n",
    "    \n",
    "    # 3. ELOGIOS FORTES (Override POSITIVO)\n",
    "    if any(word in texto_lower for word in ['recomendo', 'excelente', 'perfeito', 'adorei', '√≥timo', 'maravilhoso']):\n",
    "        # Evitar classifica√ß√£o positiva se houver nega√ß√£o muito pr√≥xima\n",
    "        if not any(neg in texto_lower for neg in ['n√£o', 'nem', 'mas']):\n",
    "             return 'POSITIVO', 'Regra_Elogio', max(confianca_ml, 0.99)\n",
    "\n",
    "    # 4. DEFAULT: Textos curtos e neutros\n",
    "    palavras = texto_lower.split()\n",
    "    if len(palavras) <= 5:\n",
    "        if any(pal in texto_lower for pal in ['recebi', 'chegou', 'entregue', 'aguardando', 'produto']):\n",
    "            if not any(neg in texto_lower for neg in ['n√£o', 'nada']):\n",
    "                # Se o ML n√£o for neutro e a confian√ßa for baixa, for√ßar NEUTRO\n",
    "                if classe_ml != 'NEUTRO' and confianca_ml < 0.8:\n",
    "                    return 'NEUTRO', 'Regra_Curto', max(confianca_ml, 0.80)\n",
    "\n",
    "    # REGRA 7: Se termina com \"mas gostei\" = POSITIVO (apesar do problema)\n",
    "    if 'mas' in texto_lower and 'gostei' in texto_lower.split('mas')[-1]:\n",
    "        return 'POSITIVO', 'Regra_Mas_Pos', max(confianca_ml, 0.90)\n",
    "\n",
    "    # Se nenhuma regra se aplica, confiar na classifica√ß√£o do ML\n",
    "    return classe_ml, 'ML', confianca_ml\n",
    "\n",
    "\n",
    "# --- RESTANTE DO C√ìDIGO (1 a 6: TREINAMENTO DO ML) ---\n",
    "# ... (Manter os passos 1 a 6 sem altera√ß√£o) ...\n",
    "\n",
    "# 1. Carregar suas 400 classifica√ß√µes\n",
    "caminho_400 = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\classificacao_manual_400.xlsx'\n",
    "try:\n",
    "    df_classificado = pd.read_excel(caminho_400, sheet_name='Classificar')\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Arquivo de classifica√ß√£o manual n√£o encontrado em: {caminho_400}\")\n",
    "    exit()\n",
    "\n",
    "# ... (Manter o restante da Fase 1 e 2: Carregamento e combina√ß√£o de datasets) ...\n",
    "df_classificado = df_classificado[df_classificado['Classificacao_Manual'].notna()]\n",
    "df_classificado['Classificacao_Manual'] = df_classificado['Classificacao_Manual'].str.strip().str.upper()\n",
    "\n",
    "caminho_validacoes_antigas = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\validacao_manual_final.xlsx'\n",
    "try:\n",
    "    validacoes_anteriores = pd.read_excel(caminho_validacoes_antigas, sheet_name='Classificar')\n",
    "    validacoes_anteriores = validacoes_anteriores[validacoes_anteriores['Classificacao_Manual'].notna()]\n",
    "    df_treino = pd.concat([\n",
    "        df_classificado.rename(columns={'Comentario': 'Msg_coment√°rio'}), \n",
    "        validacoes_anteriores[['Msg_coment√°rio', 'Classificacao_Manual']]\n",
    "    ], ignore_index=True).drop_duplicates(subset=['Msg_coment√°rio'])\n",
    "except:\n",
    "    df_treino = df_classificado.rename(columns={'Comentario': 'Msg_coment√°rio'})\n",
    "print(f\"Total de amostras de treino para ML: {len(df_treino)}\")\n",
    "\n",
    "# 3. Pr√©-processamento (fun√ß√£o simples)\n",
    "def preprocessar_simples(textos):\n",
    "    processados = []\n",
    "    for texto in textos:\n",
    "        texto = str(texto).lower()\n",
    "        texto = re.sub(r'[^a-z√°√†√¢√£√©√™√≠√≥√¥√µ√∫√º√ß0-9\\s]', ' ', texto) \n",
    "        texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "        processados.append(texto)\n",
    "    return processados\n",
    "\n",
    "# 4. Treinar modelo\n",
    "X = preprocessar_simples(df_treino['Msg_coment√°rio'].values)\n",
    "y = df_treino['Classificacao_Manual'].values\n",
    "try:\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "except:\n",
    "    stop_words = []\n",
    "vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2), stop_words=stop_words, min_df=2, max_df=0.9)\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42, stratify=y)\n",
    "model = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced', C=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Avaliar e 6. Salvar modelo\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Acur√°cia do ML puro (Teste/Valida√ß√£o): {accuracy:.1%}\")\n",
    "\n",
    "modelo_final = {'model': model, 'vectorizer': vectorizer, 'acuracia': accuracy, 'tamanho_treino': len(df_treino), 'data_treinamento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "caminho_modelo_final = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\modelo_400_classificacoes_hibrido.pkl'\n",
    "with open(caminho_modelo_final, 'wb') as f:\n",
    "    pickle.dump(modelo_final, f)\n",
    "print(f\"üíæ Modelo ML puro salvo em: {caminho_modelo_final}\")\n",
    "\n",
    "\n",
    "# --- PASSO 7: APLICA√á√ÉO E CORRE√á√ÉO H√çBRIDA ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚öôÔ∏è APLICANDO MODELO H√çBRIDO (ML + REGRAS) AO DATASET COMPLETO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "caminho_dataset_completo = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\olist_avaliacoes.xlsx'\n",
    "try:\n",
    "    df_completo = pd.read_excel(caminho_dataset_completo)\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Erro: Dataset completo n√£o encontrado em: {caminho_dataset_completo}\")\n",
    "    exit()\n",
    "\n",
    "# 7.1. Classifica√ß√£o pelo ML Puro\n",
    "textos_completos = df_completo['Msg_coment√°rio'].fillna('').astype(str).values\n",
    "textos_proc_completos = preprocessar_simples(textos_completos)\n",
    "\n",
    "X_todo = vectorizer.transform(textos_proc_completos)\n",
    "predicoes_ml = model.predict(X_todo)\n",
    "probabilidades = model.predict_proba(X_todo)\n",
    "confiancas_ml = np.max(probabilidades, axis=1)\n",
    "\n",
    "df_completo['Sentimento_ML'] = predicoes_ml\n",
    "df_completo['Confianca_ML'] = confiancas_ml\n",
    "\n",
    "# 7.2. Aplica√ß√£o do Override pelas Regras H√≠bridas\n",
    "resultados_hibridos = []\n",
    "for index, row in df_completo.iterrows():\n",
    "    texto = row['Msg_coment√°rio']\n",
    "    classe_ml = row['Sentimento_ML']\n",
    "    confianca_ml = row['Confianca_ML']\n",
    "    \n",
    "    # Aplica a Regra de Override\n",
    "    classe_final, metodo_final, confianca_final = classificar_manual_corretamente(\n",
    "        texto, classe_ml, confianca_ml\n",
    "    )\n",
    "    resultados_hibridos.append((classe_final, metodo_final, confianca_final))\n",
    "\n",
    "# Adicionar resultados corrigidos ao DataFrame\n",
    "df_completo['Sentimento_Final'] = [r[0] for r in resultados_hibridos]\n",
    "df_completo['Metodo'] = [r[1] for r in resultados_hibridos]\n",
    "df_completo['Confianca_Final'] = [r[2] for r in resultados_hibridos]\n",
    "\n",
    "# 7.3. Ajustar os coment√°rios vazios/ausentes\n",
    "mask_vazios = (df_completo['Msg_coment√°rio'].isna()) | (df_completo['Msg_coment√°rio'].str.strip() == '')\n",
    "df_completo.loc[mask_vazios, 'Sentimento_Final'] = 'NEUTRO_VAZIO'\n",
    "df_completo.loc[mask_vazios, 'Metodo'] = 'SEM_COMENTARIO'\n",
    "df_completo.loc[mask_vazios, 'Confianca_Final'] = 1.0\n",
    "\n",
    "\n",
    "# --- PASSO 8: SALVAR E ESTAT√çSTICAS FINAIS ---\n",
    "caminho_final_resultados = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\resultados_finais_HIBRIDOS.xlsx'\n",
    "df_completo.to_excel(caminho_final_resultados, index=False)\n",
    "\n",
    "print(f\"‚úÖ Resultados H√çBRIDOS (ML corrigido) salvos: {caminho_final_resultados}\")\n",
    "\n",
    "# Estat√≠sticas Finais\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä ESTAT√çSTICAS FINAIS DO MODELO H√çBRIDO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Distribui√ß√£o dos coment√°rios v√°lidos (excluindo neutro vazio)\n",
    "df_validos = df_completo[df_completo['Sentimento_Final'] != 'NEUTRO_VAZIO']\n",
    "distrib = df_validos['Sentimento_Final'].value_counts()\n",
    "total_classificado = distrib.sum()\n",
    "print(f\"Distribui√ß√£o dos {total_classificado:,} coment√°rios classificados:\")\n",
    "\n",
    "# Contagem de corre√ß√µes por regra\n",
    "correcoes = df_validos[df_validos['Metodo'] != 'ML']['Metodo'].value_counts()\n",
    "total_correcoes = correcoes.sum()\n",
    "\n",
    "for cat, qtd in distrib.items():\n",
    "    perc = qtd / total_classificado * 100\n",
    "    print(f\"  {cat}: {qtd:,} ({perc:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Total de Corre√ß√µes por Regra (Override): {total_correcoes:,} ({total_correcoes/total_classificado*100:.1f}%)\")\n",
    "print(correcoes.to_string())\n",
    "\n",
    "conf_media = df_validos['Confianca_Final'].mean()\n",
    "print(f\"\\nüé≠ Confian√ßa M√©dia Final: {conf_media:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PROCESSO H√çBRIDO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"======================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471c7fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä GERANDO AN√ÅLISES DE BI PARA DASHBOARD\n",
      "======================================================================\n",
      "üì¶ Carregando dados e classificando...\n",
      "Total de registros: 99,224\n",
      "Coment√°rios v√°lidos: 40,950\n",
      "Vazios: 58,274\n",
      "  Classificados: 60,000/40,950\n",
      "  Classificados: 65,000/40,950\n",
      "  Classificados: 70,000/40,950\n",
      "  Classificados: 75,000/40,950\n",
      "  Classificados: 80,000/40,950\n",
      "  Classificados: 85,000/40,950\n",
      "  Classificados: 90,000/40,950\n",
      "  Classificados: 95,000/40,950\n",
      "\n",
      "‚úÖ Classifica√ß√£o conclu√≠da!\n",
      "\n",
      "üìã Criando Aba 1: Base_com_Sentimento...\n",
      "üìã Criando Aba 2: Top_10_Reclamacoes...\n",
      "üìã Criando Aba 3: Resumo_Sentimento...\n",
      "üìã Criando Aba 4: Top_20_Geral...\n",
      "üìã Criando Aba 5: Analise_Confianca...\n",
      "\n",
      "üíæ Salvando an√°lises em: C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\analises_bi_completas.xlsx\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Worksheet' object has no attribute '_shared_strings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 367\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sheet_name \u001b[38;5;129;01min\u001b[39;00m writer\u001b[38;5;241m.\u001b[39msheets:\n\u001b[0;32m    366\u001b[0m     worksheet \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39msheets[sheet_name]\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(writer\u001b[38;5;241m.\u001b[39msheets[sheet_name]\u001b[38;5;241m.\u001b[39m_shared_strings):\n\u001b[0;32m    368\u001b[0m         column_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(col)), \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    369\u001b[0m         worksheet\u001b[38;5;241m.\u001b[39mset_column(i, i, \u001b[38;5;28mmin\u001b[39m(column_len, \u001b[38;5;241m50\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Worksheet' object has no attribute '_shared_strings'"
     ]
    }
   ],
   "source": [
    "# --- AN√ÅLISES DE BI COM MODELO TREINADO ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä GERANDO AN√ÅLISES DE BI PARA DASHBOARD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- CONFIGURA√á√ïES ---\n",
    "CAMINHO_MODELO = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\modelo_400_classificacoes_hibrido.pkl'\n",
    "CAMINHO_DADOS = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\olist_avaliacoes.xlsx'\n",
    "CAMINHO_RESULTADOS = r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\analises_bi_completas.xlsx'\n",
    "\n",
    "# --- CLASSE DO CLASSIFICADOR (MESMA DO ANTERIOR) ---\n",
    "class ClassificadorSentimentos:\n",
    "    def __init__(self, caminho_modelo=CAMINHO_MODELO):\n",
    "        with open(caminho_modelo, 'rb') as f:\n",
    "            self.modelo = pickle.load(f)\n",
    "        self.ml_model = self.modelo['model']\n",
    "        self.vectorizer = self.modelo['vectorizer']\n",
    "    \n",
    "    def classificar_texto(self, texto):\n",
    "        if not isinstance(texto, str) or texto.strip() == '':\n",
    "            return 'NEUTRO', 'SEM_TEXTO', 1.0\n",
    "        \n",
    "        texto_lower = texto.lower()\n",
    "        \n",
    "        # Regras absolutas\n",
    "        if 'n√£o recomendo' in texto_lower:\n",
    "            return 'NEGATIVO', 'REGRA_NAO_RECOMENDO', 0.98\n",
    "        if 'n√£o gostei' in texto_lower:\n",
    "            return 'NEGATIVO', 'REGRA_NAO_GOSTEI', 0.97\n",
    "        if 'excelente' in texto_lower:\n",
    "            pos = texto_lower.find('excelente')\n",
    "            if pos > 0 and not any(neg in texto_lower[:pos] for neg in ['n√£o', 'nem', 'mas']):\n",
    "                return 'POSITIVO', 'REGRA_EXCELENTE', 0.96\n",
    "        if 'defeito' in texto_lower:\n",
    "            return 'NEGATIVO', 'REGRA_DEFEITO', 0.93\n",
    "        if any(pal in texto_lower for pal in ['atraso', 'demorou', 'demora']):\n",
    "            if 'mas' in texto_lower and 'gostei' in texto_lower.split('mas')[-1]:\n",
    "                return 'POSITIVO', 'REGRA_MAS_POSITIVO', 0.85\n",
    "            return 'NEGATIVO', 'REGRA_ATRASO', 0.88\n",
    "        \n",
    "        palavras = texto_lower.split()\n",
    "        if len(palavras) <= 5:\n",
    "            if any(pal in texto_lower for pal in ['recebi', 'chegou', 'entregue', 'produto', 'ok']):\n",
    "                return 'NEUTRO', 'REGRA_TEXTO_CURTO', 0.82\n",
    "        \n",
    "        # ML\n",
    "        texto_proc = texto_lower\n",
    "        texto_proc = re.sub(r'[^a-z√°√†√¢√£√©√™√≠√≥√¥√µ√∫√º√ß0-9\\s]', ' ', texto_proc)\n",
    "        texto_proc = re.sub(r'\\s+', ' ', texto_proc).strip()\n",
    "        \n",
    "        X = self.vectorizer.transform([texto_proc])\n",
    "        predicao = self.ml_model.predict(X)[0]\n",
    "        proba = self.ml_model.predict_proba(X)[0]\n",
    "        confianca = max(proba)\n",
    "        \n",
    "        if confianca >= 0.7:\n",
    "            return predicao, 'ML_ALTA_CONF', confianca\n",
    "        else:\n",
    "            return predicao, 'ML_BAIXA_CONF', confianca\n",
    "\n",
    "# --- CARREGAR E CLASSIFICAR DADOS ---\n",
    "print(\"üì¶ Carregando dados e classificando...\")\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_excel(CAMINHO_DADOS)\n",
    "print(f\"Total de registros: {len(df):,}\")\n",
    "\n",
    "# Separar v√°lidos e vazios\n",
    "mask_valido = df['Msg_coment√°rio'].notna() & (df['Msg_coment√°rio'].astype(str).str.strip() != '')\n",
    "df_validos = df[mask_valido].copy()\n",
    "df_vazios = df[~mask_valido].copy()\n",
    "\n",
    "print(f\"Coment√°rios v√°lidos: {len(df_validos):,}\")\n",
    "print(f\"Vazios: {len(df_vazios):,}\")\n",
    "\n",
    "# Classificar\n",
    "classificador = ClassificadorSentimentos()\n",
    "resultados = []\n",
    "\n",
    "for i, row in df_validos.iterrows():\n",
    "    texto = str(row['Msg_coment√°rio'])\n",
    "    sentimento, metodo, confianca = classificador.classificar_texto(texto)\n",
    "    resultados.append((sentimento, metodo, confianca))\n",
    "    \n",
    "    # Progresso\n",
    "    if (i + 1) % 5000 == 0:\n",
    "        print(f\"  Classificados: {i + 1:,}/{len(df_validos):,}\")\n",
    "\n",
    "# Adicionar aos v√°lidos\n",
    "df_validos['Sentimento'] = [r[0] for r in resultados]\n",
    "df_validos['Metodo_Classificacao'] = [r[1] for r in resultados]\n",
    "df_validos['Confianca'] = [r[2] for r in resultados]\n",
    "\n",
    "# Vazios = neutro\n",
    "df_vazios['Sentimento'] = 'NEUTRO'\n",
    "df_vazios['Metodo_Classificacao'] = 'SEM_COMENTARIO'\n",
    "df_vazios['Confianca'] = 1.0\n",
    "\n",
    "# Juntar tudo\n",
    "df_completo = pd.concat([df_validos, df_vazios], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Classifica√ß√£o conclu√≠da!\")\n",
    "\n",
    "# --- ABA 1: BASE COM SENTIMENTO ---\n",
    "print(\"\\nüìã Criando Aba 1: Base_com_Sentimento...\")\n",
    "\n",
    "# Manter colunas importantes para an√°lise\n",
    "colunas_manter = [\n",
    "    'Msg_coment√°rio', 'Sentimento', 'Metodo_Classificacao', 'Confianca'\n",
    "]\n",
    "\n",
    "# Adicionar outras colunas se existirem\n",
    "colunas_existentes = df_completo.columns.tolist()\n",
    "colunas_adicionais = [c for c in colunas_existentes \n",
    "                     if c not in colunas_manter and c != 'Unnamed: 0']\n",
    "\n",
    "df_base = df_completo[colunas_manter + colunas_adicionais].copy()\n",
    "\n",
    "# --- ABA 2: TOP 10 RECLAMA√á√ïES ---\n",
    "print(\"üìã Criando Aba 2: Top_10_Reclamacoes...\")\n",
    "\n",
    "# Filtrar negativos\n",
    "df_negativos = df_validos[df_validos['Sentimento'] == 'NEGATIVO'].copy()\n",
    "\n",
    "# Limpar texto para an√°lise\n",
    "def limpar_texto_analise(texto):\n",
    "    texto = str(texto).lower()\n",
    "    texto = re.sub(r'[^a-z√°√†√¢√£√©√™√≠√≥√¥√µ√∫√º√ß0-9\\s]', ' ', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    return texto\n",
    "\n",
    "df_negativos['texto_limpo'] = df_negativos['Msg_coment√°rio'].apply(limpar_texto_analise)\n",
    "\n",
    "# Identificar palavras-chave de problemas\n",
    "palavras_chave_problemas = {\n",
    "    'atraso': ['atraso', 'demorou', 'demora', 'tarde', 'prazo'],\n",
    "    'defeito': ['defeito', 'quebrado', 'quebrou', 'quebrada', 'quebrados'],\n",
    "    'entregue': ['n√£o entregue', 'n√£o chegou', 'n√£o recebi'],\n",
    "    'qualidade': ['ruim', 'p√©ssimo', 'horr√≠vel', 'baixa qualidade', 'qualidade ruim'],\n",
    "    'errado': ['errado', 'diferente', 'outro modelo', 'n√£o √© o que comprei'],\n",
    "    'faltando': ['faltando', 's√≥ veio', 'n√£o veio', 'incompleto'],\n",
    "    'frete': ['frete caro', 'transporte', 'entrega cara'],\n",
    "    'embalagem': ['embalagem', 'amassado', 'rasgado', 'avariado'],\n",
    "    'contato': ['n√£o responde', 'n√£o atende', 'sem resposta', 'contato'],\n",
    "    'cancelamento': ['cancelar', 'devolu√ß√£o', 'reembolso', 'troca']\n",
    "}\n",
    "\n",
    "# Contar ocorr√™ncias de cada tipo de problema\n",
    "problemas_contagem = {}\n",
    "for problema, palavras in palavras_chave_problemas.items():\n",
    "    contagem = 0\n",
    "    for texto in df_negativos['texto_limpo']:\n",
    "        if any(palavra in texto for palavra in palavras):\n",
    "            contagem += 1\n",
    "    problemas_contagem[problema] = contagem\n",
    "\n",
    "# Criar DataFrame de problemas\n",
    "df_problemas = pd.DataFrame({\n",
    "    'Tipo_Problema': list(problemas_contagem.keys()),\n",
    "    'Quantidade': list(problemas_contagem.values()),\n",
    "    'Percentual': [q/len(df_negativos)*100 for q in problemas_contagem.values()]\n",
    "}).sort_values('Quantidade', ascending=False).head(10)\n",
    "\n",
    "# Exemplos de cada problema\n",
    "exemplos_problemas = []\n",
    "for problema in df_problemas['Tipo_Problema'].head(5):\n",
    "    exemplos = df_negativos[\n",
    "        df_negativos['texto_limpo'].str.contains('|'.join(palavras_chave_problemas[problema]))\n",
    "    ].head(3)\n",
    "    \n",
    "    for _, row in exemplos.iterrows():\n",
    "        exemplos_problemas.append({\n",
    "            'Tipo_Problema': problema,\n",
    "            'Exemplo': row['Msg_coment√°rio'][:150] + ('...' if len(row['Msg_coment√°rio']) > 150 else ''),\n",
    "            'Confianca_Classificacao': f\"{row['Confianca']:.1%}\"\n",
    "        })\n",
    "\n",
    "df_exemplos_problemas = pd.DataFrame(exemplos_problemas)\n",
    "\n",
    "# --- ABA 3: RESUMO SENTIMENTO ---\n",
    "print(\"üìã Criando Aba 3: Resumo_Sentimento...\")\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "total_geral = len(df_completo)\n",
    "total_validos = len(df_validos)\n",
    "total_vazios = len(df_vazios)\n",
    "\n",
    "# Distribui√ß√£o de sentimentos (apenas v√°lidos)\n",
    "distrib_sentimentos = df_validos['Sentimento'].value_counts()\n",
    "distrib_percentual = df_validos['Sentimento'].value_counts(normalize=True) * 100\n",
    "\n",
    "# M√©todos de classifica√ß√£o\n",
    "distrib_metodos = df_validos['Metodo_Classificacao'].value_counts()\n",
    "distrib_metodos_perc = df_validos['Metodo_Classificacao'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Confian√ßa m√©dia por sentimento\n",
    "confianca_media = df_validos.groupby('Sentimento')['Confianca'].mean()\n",
    "confianca_geral = df_validos['Confianca'].mean()\n",
    "\n",
    "# Criar DataFrame resumo\n",
    "df_resumo = pd.DataFrame({\n",
    "    'Metrica': [\n",
    "        'Total Registros', 'Coment√°rios V√°lidos', 'Registros Sem Coment√°rio',\n",
    "        'POSITIVO (Quantidade)', 'POSITIVO (%)', \n",
    "        'NEGATIVO (Quantidade)', 'NEGATIVO (%)',\n",
    "        'NEUTRO (Quantidade)', 'NEUTRO (%)',\n",
    "        'Confian√ßa M√©dia Geral', 'Confian√ßa M√©dia POSITIVO',\n",
    "        'Confian√ßa M√©dia NEGATIVO', 'Confian√ßa M√©dia NEUTRO',\n",
    "        'Acur√°cia Modelo (Treino)', 'Data Processamento'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        f\"{total_geral:,}\",\n",
    "        f\"{total_validos:,}\",\n",
    "        f\"{total_vazios:,}\",\n",
    "        f\"{distrib_sentimentos.get('POSITIVO', 0):,}\",\n",
    "        f\"{distrib_percentual.get('POSITIVO', 0):.1f}%\",\n",
    "        f\"{distrib_sentimentos.get('NEGATIVO', 0):,}\",\n",
    "        f\"{distrib_percentual.get('NEGATIVO', 0):.1f}%\",\n",
    "        f\"{distrib_sentimentos.get('NEUTRO', 0):,}\",\n",
    "        f\"{distrib_percentual.get('NEUTRO', 0):.1f}%\",\n",
    "        f\"{confianca_geral:.1%}\",\n",
    "        f\"{confianca_media.get('POSITIVO', 0):.1%}\",\n",
    "        f\"{confianca_media.get('NEGATIVO', 0):.1%}\",\n",
    "        f\"{confianca_media.get('NEUTRO', 0):.1%}\",\n",
    "        f\"{classificador.modelo.get('acuracia', 'N/A'):.1%}\",\n",
    "        datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    ]\n",
    "})\n",
    "\n",
    "# --- ABA 4: TOP 20 GERAL ---\n",
    "print(\"üìã Criando Aba 4: Top_20_Geral...\")\n",
    "\n",
    "# Fun√ß√£o para extrair palavras-chave\n",
    "def extrair_palavras_chave(texto, n_palavras=3):\n",
    "    texto = str(texto).lower()\n",
    "    palavras = texto.split()\n",
    "    \n",
    "    # Remover stopwords simples\n",
    "    stopwords = ['o', 'a', 'os', 'as', 'um', 'uma', 'uns', 'umas',\n",
    "                'de', 'do', 'da', 'dos', 'das', 'em', 'no', 'na',\n",
    "                'nos', 'nas', 'por', 'para', 'com', 'sem', 'sob',\n",
    "                'sobre', 'entre', 'que', 'e', 'mas', 'por√©m']\n",
    "    \n",
    "    palavras_filtradas = [p for p in palavras if p not in stopwords and len(p) > 2]\n",
    "    \n",
    "    # Pegar as n palavras mais frequentes\n",
    "    if len(palavras_filtradas) >= n_palavras:\n",
    "        return ' '.join(palavras_filtradas[:n_palavras])\n",
    "    return ' '.join(palavras_filtradas)\n",
    "\n",
    "# Para cada sentimento, pegar os mais representativos\n",
    "top_comentarios = []\n",
    "\n",
    "for sentimento in ['POSITIVO', 'NEGATIVO', 'NEUTRO']:\n",
    "    # Pegar com maior confian√ßa\n",
    "    df_sentimento = df_validos[df_validos['Sentimento'] == sentimento]\n",
    "    \n",
    "    # Ordenar por confian√ßa\n",
    "    top_confianca = df_sentimento.nlargest(7, 'Confianca')\n",
    "    \n",
    "    for _, row in top_confianca.iterrows():\n",
    "        palavras_chave = extrair_palavras_chave(row['Msg_coment√°rio'], 3)\n",
    "        top_comentarios.append({\n",
    "            'Sentimento': sentimento,\n",
    "            'Comentario': row['Msg_coment√°rio'][:120] + ('...' if len(row['Msg_coment√°rio']) > 120 else ''),\n",
    "            'Palavras_Chave': palavras_chave,\n",
    "            'Confianca': f\"{row['Confianca']:.1%}\",\n",
    "            'Metodo': row['Metodo_Classificacao']\n",
    "        })\n",
    "    \n",
    "    # Pegar mais curtos (para ver padr√µes)\n",
    "    df_sentimento['tamanho'] = df_sentimento['Msg_coment√°rio'].str.len()\n",
    "    top_curtos = df_sentimento.nsmallest(3, 'tamanho')\n",
    "    \n",
    "    for _, row in top_curtos.iterrows():\n",
    "        if len(row['Msg_coment√°rio']) > 10:  # Evitar muito curtos\n",
    "            palavras_chave = extrair_palavras_chave(row['Msg_coment√°rio'], 3)\n",
    "            top_comentarios.append({\n",
    "                'Sentimento': sentimento,\n",
    "                'Comentario': row['Msg_coment√°rio'],\n",
    "                'Palavras_Chave': palavras_chave,\n",
    "                'Confianca': f\"{row['Confianca']:.1%}\",\n",
    "                'Metodo': row['Metodo_Classificacao']\n",
    "            })\n",
    "\n",
    "df_top_geral = pd.DataFrame(top_comentarios).head(20)\n",
    "\n",
    "# --- ABA 5: AN√ÅLISE CONFIAN√áA ---\n",
    "print(\"üìã Criando Aba 5: Analise_Confianca...\")\n",
    "\n",
    "# An√°lise de confian√ßa por m√©todo\n",
    "confianca_por_metodo = df_validos.groupby('Metodo_Classificacao').agg({\n",
    "    'Confianca': ['mean', 'count'],\n",
    "    'Sentimento': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'N/A'\n",
    "}).round(3)\n",
    "\n",
    "confianca_por_metodo.columns = ['Confianca_Media', 'Quantidade', 'Sentimento_Mais_Comum']\n",
    "confianca_por_metodo = confianca_por_metodo.reset_index()\n",
    "\n",
    "# Distribui√ß√£o de confian√ßa\n",
    "bins = [0, 0.3, 0.5, 0.7, 0.85, 1.0]\n",
    "labels = ['Muito Baixa (0-30%)', 'Baixa (30-50%)', 'Media (50-70%)', \n",
    "          'Alta (70-85%)', 'Muito Alta (85-100%)']\n",
    "\n",
    "df_validos['Faixa_Confianca'] = pd.cut(df_validos['Confianca'], bins=bins, labels=labels)\n",
    "distrib_confianca = df_validos['Faixa_Confianca'].value_counts().reset_index()\n",
    "distrib_confianca.columns = ['Faixa_Confianca', 'Quantidade']\n",
    "\n",
    "# Sentimento por faixa de confian√ßa\n",
    "sentimento_por_confianca = pd.crosstab(\n",
    "    df_validos['Faixa_Confianca'], \n",
    "    df_validos['Sentimento'],\n",
    "    normalize='index'\n",
    ").round(3) * 100\n",
    "\n",
    "sentimento_por_confianca = sentimento_por_confianca.reset_index()\n",
    "\n",
    "# --- SALVAR TODAS AS ABAS ---\n",
    "print(f\"\\nüíæ Salvando an√°lises em: {CAMINHO_RESULTADOS}\")\n",
    "\n",
    "with pd.ExcelWriter(CAMINHO_RESULTADOS, engine='xlsxwriter') as writer:\n",
    "    # Aba 1: Base completa com sentimentos\n",
    "    df_base.to_excel(writer, sheet_name='Base_com_Sentimento', index=False)\n",
    "    \n",
    "    # Aba 2: Top 10 problemas\n",
    "    df_problemas.to_excel(writer, sheet_name='Top_10_Reclamacoes', index=False)\n",
    "    \n",
    "    # Se houver exemplos, salvar em sub-aba\n",
    "    if len(df_exemplos_problemas) > 0:\n",
    "        df_exemplos_problemas.to_excel(writer, sheet_name='Exemplos_Problemas', index=False)\n",
    "    \n",
    "    # Aba 3: Resumo estat√≠stico\n",
    "    df_resumo.to_excel(writer, sheet_name='Resumo_Sentimento', index=False)\n",
    "    \n",
    "    # Aba 4: Top 20 geral\n",
    "    df_top_geral.to_excel(writer, sheet_name='Top_20_Geral', index=False)\n",
    "    \n",
    "    # Aba 5: An√°lise de confian√ßa\n",
    "    confianca_por_metodo.to_excel(writer, sheet_name='Confianca_por_Metodo', index=False)\n",
    "    distrib_confianca.to_excel(writer, sheet_name='Distribuicao_Confianca', index=False)\n",
    "    sentimento_por_confianca.to_excel(writer, sheet_name='Sentimento_por_Confianca', index=False)\n",
    "    \n",
    "    # Formata√ß√£o\n",
    "    workbook = writer.book\n",
    "    \n",
    "    # Formato para percentuais\n",
    "    percent_format = workbook.add_format({'num_format': '0.0%'})\n",
    "    \n",
    "    # Formatar aba de resumo\n",
    "    worksheet_resumo = writer.sheets['Resumo_Sentimento']\n",
    "    for row_num in range(1, len(df_resumo) + 1):\n",
    "        if any(x in df_resumo.iloc[row_num-1, 0] for x in ['%', 'Confian√ßa']):\n",
    "            worksheet_resumo.write(row_num, 1, df_resumo.iloc[row_num-1, 1])\n",
    "    \n",
    "    # Autoajustar colunas\n",
    "    for sheet_name in writer.sheets:\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "        for i, col in enumerate(writer.sheets[sheet_name]._shared_strings):\n",
    "            column_len = max(len(str(col)), 10)\n",
    "            worksheet.set_column(i, i, min(column_len, 50))\n",
    "\n",
    "print(\"‚úÖ An√°lises salvas com sucesso!\")\n",
    "\n",
    "# --- RELAT√ìRIO FINAL ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RELAT√ìRIO DAS AN√ÅLISES GERADAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ ARQUIVO GERADO: {CAMINHO_RESULTADOS}\")\n",
    "print(\"\\nüìã ABAS DISPON√çVEIS PARA BI:\")\n",
    "\n",
    "abas_info = [\n",
    "    (\"1. Base_com_Sentimento\", \"Base completa com classifica√ß√µes\", \"Filtros, gr√°ficos gerais\"),\n",
    "    (\"2. Top_10_Reclamacoes\", \"Principais tipos de problemas\", \"Dashboard de melhorias\"),\n",
    "    (\"3. Resumo_Sentimento\", \"M√©tricas e estat√≠sticas\", \"KPIs e resumo executivo\"),\n",
    "    (\"4. Top_20_Geral\", \"Exemplos representativos\", \"Valida√ß√£o e exemplos\"),\n",
    "    (\"5. Confianca_por_Metodo\", \"Qualidade das classifica√ß√µes\", \"Monitoramento do modelo\"),\n",
    "    (\"6. Exemplos_Problemas\", \"Exemplos de cada problema\", \"An√°lise qualitativa\")\n",
    "]\n",
    "\n",
    "for nome, descricao, uso in abas_info:\n",
    "    print(f\"\\n   üìÑ {nome}\")\n",
    "    print(f\"      Descri√ß√£o: {descricao}\")\n",
    "    print(f\"      Uso no BI: {uso}\")\n",
    "\n",
    "print(f\"\\nüìà ESTAT√çSTICAS PRINCIPAIS:\")\n",
    "print(f\"   ‚Ä¢ Total classificados: {total_validos:,}\")\n",
    "print(f\"   ‚Ä¢ Distribui√ß√£o: {distrib_sentimentos.get('POSITIVO', 0):,} POS, \"\n",
    "      f\"{distrib_sentimentos.get('NEGATIVO', 0):,} NEG, \"\n",
    "      f\"{distrib_sentimentos.get('NEUTRO', 0):,} NEU\")\n",
    "print(f\"   ‚Ä¢ Confian√ßa m√©dia: {confianca_geral:.1%}\")\n",
    "print(f\"   ‚Ä¢ Principais problemas: {', '.join(df_problemas['Tipo_Problema'].head(3).tolist())}\")\n",
    "\n",
    "print(\"\"\"\n",
    "======================================================================\n",
    "üéØ COMO USAR NO BI:\n",
    "======================================================================\n",
    "\n",
    "1. üìä POWER BI / TABLEAU:\n",
    "   ‚Ä¢ Conecte ao arquivo Excel\n",
    "   ‚Ä¢ Use 'Base_com_Sentimento' como tabela fato\n",
    "   ‚Ä¢ Use outras abas como dimens√µes\n",
    "\n",
    "2. üìà DASHBOARDS SUGERIDOS:\n",
    "   ‚Ä¢ Painel de Satisfa√ß√£o (NPS virtual)\n",
    "   ‚Ä¢ Mapa de Problemas Recorrentes\n",
    "   ‚Ä¢ Evolu√ß√£o Temporal (se tiver datas)\n",
    "   ‚Ä¢ Top Lojas/Vendedores (se tiver esses dados)\n",
    "\n",
    "3. üîî ALERTAS AUTOM√ÅTICOS:\n",
    "   ‚Ä¢ Aumento s√∫bito de negativos\n",
    "   ‚Ä¢ Novos tipos de problemas\n",
    "   ‚Ä¢ Queda na confian√ßa do modelo\n",
    "\n",
    "4. üìã A√á√ïES RECOMENDADAS:\n",
    "   ‚Ä¢ Analisar Top_10_Reclamacoes mensalmente\n",
    "   ‚Ä¢ Validar Top_20_Geral para checar qualidade\n",
    "   ‚Ä¢ Monitorar Confianca_por_Metodo\n",
    "\n",
    "üí° DICA: Atualize mensalmente com novos dados!\n",
    "   Basta rodar este c√≥digo novamente.\n",
    "\"\"\")\n",
    "\n",
    "# --- C√ìDIGO PARA ATUALIZA√á√ÉO MENSAL ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ C√ìDIGO PARA ATUALIZA√á√ÉO MENSAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "codigo_atualizacao = '''\n",
    "# Para atualizar mensalmente, basta:\n",
    "# 1. Colocar novos dados em olist_avaliacoes.xlsx\n",
    "# 2. Executar este script novamente\n",
    "\n",
    "# Ou criar um script autom√°tico:\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "def atualizar_analises_mensal():\n",
    "    print(f\"Atualizando an√°lises em {datetime.now()}\")\n",
    "    # Coloque todo o c√≥digo acima aqui\n",
    "    print(\"‚úÖ An√°lises atualizadas!\")\n",
    "\n",
    "# Agendar para todo dia 1¬∫ do m√™s\n",
    "schedule.every().month.at(\"08:00\").do(atualizar_analises_mensal)\n",
    "\n",
    "print(\"Agendado atualiza√ß√£o mensal...\")\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(3600)  # Verifica a cada hora\n",
    "'''\n",
    "\n",
    "print(codigo_atualizacao)\n",
    "print(\"\\n‚úÖ PRONTO PARA USAR NO SEU BI! üöÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770c451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ DASHBOARD DE A√á√ïES - PRIORIDADES IDENTIFICADAS\n",
      "======================================================================\n",
      "\n",
      "üìã RESUMO EXECUTIVO PARA GESTORES:\n",
      "--------------------------------------------------\n",
      "üö® ATRASO: 15.3%\n",
      "   ‚Üí 2695 ocorr√™ncias\n",
      "   ‚Üí A√ß√£o priorit√°ria necess√°ria\n",
      "üö® ENTREGUE: 10.8%\n",
      "   ‚Üí 1902 ocorr√™ncias\n",
      "   ‚Üí A√ß√£o priorit√°ria necess√°ria\n",
      "üö® CANCELAMENTO: 6.0%\n",
      "   ‚Üí 1054 ocorr√™ncias\n",
      "   ‚Üí A√ß√£o priorit√°ria necess√°ria\n",
      "‚ö†Ô∏è  ERRADO: 4.5%\n",
      "   ‚Üí 798 ocorr√™ncias\n",
      "   ‚Üí Monitorar mensalmente\n",
      "‚ö†Ô∏è  DEFEITO: 3.7%\n",
      "   ‚Üí 649 ocorr√™ncias\n",
      "   ‚Üí Monitorar mensalmente\n",
      "‚ö†Ô∏è  FALTANDO: 3.5%\n",
      "   ‚Üí 616 ocorr√™ncias\n",
      "   ‚Üí Monitorar mensalmente\n",
      "‚ö†Ô∏è  CONTATO: 3.5%\n",
      "   ‚Üí 612 ocorr√™ncias\n",
      "   ‚Üí Monitorar mensalmente\n",
      "\n",
      "üìã PLANO DE A√á√ÉO RECOMENDADO:\n",
      "--------------------------------------------------\n",
      "\n",
      "üéØ ATRASO (15.3%):\n",
      "   1. Implementar sistema de tracking em tempo real\n",
      "   2. Rever prazos de entrega divulgados\n",
      "   3. Parceria com transportadoras mais eficientes\n",
      "   4. SLA de entrega por regi√£o\n",
      "\n",
      "üéØ ENTREGUE (10.8%):\n",
      "   1. Sistema de confirma√ß√£o de entrega com foto\n",
      "   2. Notifica√ß√£o ao cliente quando marcado como entregue\n",
      "   3. Protocolo para entregas n√£o recebidas\n",
      "   4. Treinamento de entregadores\n",
      "\n",
      "üéØ CANCELAMENTO (6.0%):\n",
      "   1. An√°lise de motivo de cancelamentos\n",
      "   2. Pesquisa p√≥s-cancelamento\n",
      "   3. Pol√≠tica de reten√ß√£o para cancelamentos\n",
      "   4. Checkout otimizado\n",
      "\n",
      "üéØ ERRADO (4.5%):\n",
      "   1. Controle de qualidade na separa√ß√£o\n",
      "   2. Checklist de confer√™ncia\n",
      "   3. Sistema de c√≥digo de barras\n",
      "   4. Treinamento de equipe de warehouse\n",
      "\n",
      "üéØ DEFEITO (3.7%):\n",
      "   1. Garantia estendida\n",
      "   2. Processo r√°pido de troca\n",
      "   3. Parceria com assist√™ncia t√©cnica\n",
      "   4. Controle de qualidade de fornecedores\n",
      "\n",
      "üìã KPIs PARA MONITORAR MELHORIA:\n",
      "--------------------------------------------------\n",
      "üìä Redu√ß√£o de reclama√ß√µes por atraso\n",
      "   M√©trica: % redu√ß√£o m√™s a m√™s\n",
      "   üéØ Meta: -20% em 3 meses\n",
      "üìä Taxa de entregas confirmadas\n",
      "   M√©trica: % entregas com confirma√ß√£o\n",
      "   üéØ Meta: 95%\n",
      "üìä Taxa de cancelamento\n",
      "   M√©trica: % pedidos cancelados\n",
      "   üéØ Meta: <3%\n",
      "üìä Satisfa√ß√£o p√≥s-troca\n",
      "   M√©trica: NPS ap√≥s troca\n",
      "   üéØ Meta: >70\n",
      "üìä Tempo de resposta a contatos\n",
      "   M√©trica: Horas para resposta\n",
      "   üéØ Meta: <24h\n",
      "\n",
      "üíæ Criando dashboard completo em Excel...\n",
      "‚úÖ Dashboard salvo: dashboard_acoes.xlsx\n",
      "\n",
      "======================================================================\n",
      "üéØ RESUMO DAS DESCOBERTAS:\n",
      "======================================================================\n",
      "\n",
      "üèÜ TOP 3 PROBLEMAS (67% do esfor√ßo deve ser aqui):\n",
      "1. ATRASO (15.3%) ‚Üí Problema de LOG√çSTICA\n",
      "2. ENTREGUE (10.8%) ‚Üí Problema de SISTEMA\n",
      "3. CANCELAMENTO (6.0%) ‚Üí Problema de VENDAS\n",
      "\n",
      "üìä REGRA 80/20 APLICADA:\n",
      "‚Ä¢ Top 3 problemas = 32.1% de TODAS as reclama√ß√µes\n",
      "‚Ä¢ Focar nesses resolve 1/3 dos problemas dos clientes\n",
      "\n",
      "üí° INSIGHTS VALIOSOS:\n",
      "‚Ä¢ Clientes est√£o MUITO insatisfeitos com prazos\n",
      "‚Ä¢ Sistema de entrega tem falhas graves\n",
      "‚Ä¢ Processo de cancelamento precisa de aten√ß√£o\n",
      "\n",
      "üöÄ PR√ìXIMOS PASSOS:\n",
      "1. Apresente esses dados para a diretoria\n",
      "2. Crie squad para cada problema priorit√°rio\n",
      "3. Monitore redu√ß√£o mensalmente\n",
      "\n",
      "üéØ SEU BI AGORA TEM:\n",
      "‚Ä¢ Dados para tomar decis√µes baseadas em evid√™ncias\n",
      "‚Ä¢ Plano de a√ß√£o claro\n",
      "‚Ä¢ KPIs para medir sucesso\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- DASHBOARD DE A√á√ïES BASEADO NAS RECLAMA√á√ïES ---\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéØ DASHBOARD DE A√á√ïES - PRIORIDADES IDENTIFICADAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Seus dados\n",
    "dados_problemas = {\n",
    "    'Tipo_Problema': ['atraso', 'entregue', 'cancelamento', 'errado', 'defeito', \n",
    "                     'faltando', 'contato', 'qualidade', 'embalagem'],\n",
    "    'Quantidade': [2695, 1902, 1054, 798, 649, 616, 612, 445, 371],\n",
    "    'Percentual': [15.32, 10.81, 5.99, 4.54, 3.69, 3.50, 3.48, 2.53, 2.11]\n",
    "}\n",
    "\n",
    "df_problemas = pd.DataFrame(dados_problemas)\n",
    "\n",
    "# --- ABA 1: RESUMO EXECUTIVO ---\n",
    "print(\"\\nüìã RESUMO EXECUTIVO PARA GESTORES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for _, row in df_problemas.iterrows():\n",
    "    if row['Percentual'] > 5:\n",
    "        print(f\"üö® {row['Tipo_Problema'].upper()}: {row['Percentual']:.1f}%\")\n",
    "        print(f\"   ‚Üí {row['Quantidade']} ocorr√™ncias\")\n",
    "        print(f\"   ‚Üí A√ß√£o priorit√°ria necess√°ria\")\n",
    "    elif row['Percentual'] > 3:\n",
    "        print(f\"‚ö†Ô∏è  {row['Tipo_Problema'].upper()}: {row['Percentual']:.1f}%\")\n",
    "        print(f\"   ‚Üí {row['Quantidade']} ocorr√™ncias\")\n",
    "        print(f\"   ‚Üí Monitorar mensalmente\")\n",
    "\n",
    "# --- ABA 2: PLANO DE A√á√ÉO ---\n",
    "print(\"\\nüìã PLANO DE A√á√ÉO RECOMENDADO:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "acoes_recomendadas = {\n",
    "    'atraso': [\n",
    "        \"Implementar sistema de tracking em tempo real\",\n",
    "        \"Rever prazos de entrega divulgados\",\n",
    "        \"Parceria com transportadoras mais eficientes\",\n",
    "        \"SLA de entrega por regi√£o\"\n",
    "    ],\n",
    "    'entregue': [\n",
    "        \"Sistema de confirma√ß√£o de entrega com foto\",\n",
    "        \"Notifica√ß√£o ao cliente quando marcado como entregue\",\n",
    "        \"Protocolo para entregas n√£o recebidas\",\n",
    "        \"Treinamento de entregadores\"\n",
    "    ],\n",
    "    'cancelamento': [\n",
    "        \"An√°lise de motivo de cancelamentos\",\n",
    "        \"Pesquisa p√≥s-cancelamento\",\n",
    "        \"Pol√≠tica de reten√ß√£o para cancelamentos\",\n",
    "        \"Checkout otimizado\"\n",
    "    ],\n",
    "    'errado': [\n",
    "        \"Controle de qualidade na separa√ß√£o\",\n",
    "        \"Checklist de confer√™ncia\",\n",
    "        \"Sistema de c√≥digo de barras\",\n",
    "        \"Treinamento de equipe de warehouse\"\n",
    "    ],\n",
    "    'defeito': [\n",
    "        \"Garantia estendida\",\n",
    "        \"Processo r√°pido de troca\",\n",
    "        \"Parceria com assist√™ncia t√©cnica\",\n",
    "        \"Controle de qualidade de fornecedores\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for problema, acoes in acoes_recomendadas.items():\n",
    "    if problema in df_problemas['Tipo_Problema'].values:\n",
    "        percentual = df_problemas[df_problemas['Tipo_Problema'] == problema]['Percentual'].values[0]\n",
    "        print(f\"\\nüéØ {problema.upper()} ({percentual:.1f}%):\")\n",
    "        for i, acao in enumerate(acoes, 1):\n",
    "            print(f\"   {i}. {acao}\")\n",
    "\n",
    "# --- ABA 3: KPIs DE MELHORIA ---\n",
    "print(\"\\nüìã KPIs PARA MONITORAR MELHORIA:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "kpis = [\n",
    "    (\"Redu√ß√£o de reclama√ß√µes por atraso\", \"M√©trica: % redu√ß√£o m√™s a m√™s\", \"Meta: -20% em 3 meses\"),\n",
    "    (\"Taxa de entregas confirmadas\", \"M√©trica: % entregas com confirma√ß√£o\", \"Meta: 95%\"),\n",
    "    (\"Taxa de cancelamento\", \"M√©trica: % pedidos cancelados\", \"Meta: <3%\"),\n",
    "    (\"Satisfa√ß√£o p√≥s-troca\", \"M√©trica: NPS ap√≥s troca\", \"Meta: >70\"),\n",
    "    (\"Tempo de resposta a contatos\", \"M√©trica: Horas para resposta\", \"Meta: <24h\")\n",
    "]\n",
    "\n",
    "for kpi, metrica, meta in kpis:\n",
    "    print(f\"üìä {kpi}\")\n",
    "    print(f\"   {metrica}\")\n",
    "    print(f\"   üéØ {meta}\")\n",
    "\n",
    "# --- SALVAR DASHBOARD COMPLETO ---\n",
    "print(\"\\nüíæ Criando dashboard completo em Excel...\")\n",
    "\n",
    "with pd.ExcelWriter(r'C:\\Users\\Natasha\\Documents\\GITHUB\\olist\\dashboard_acoes.xlsx', \n",
    "                    engine='xlsxwriter') as writer:\n",
    "    \n",
    "    # Aba 1: Problemas e percentuais\n",
    "    df_problemas.to_excel(writer, sheet_name='Top_Problemas', index=False)\n",
    "    \n",
    "    # Aba 2: Plano de a√ß√£o\n",
    "    dados_acoes = []\n",
    "    for problema, acoes in acoes_recomendadas.items():\n",
    "        for acao in acoes:\n",
    "            dados_acoes.append({'Problema': problema.upper(), 'Acao': acao, 'Status': 'Pendente'})\n",
    "    df_acoes = pd.DataFrame(dados_acoes)\n",
    "    df_acoes.to_excel(writer, sheet_name='Plano_Acao', index=False)\n",
    "    \n",
    "    # Aba 3: KPIs\n",
    "    df_kpis = pd.DataFrame(kpis, columns=['KPI', 'Metrica', 'Meta'])\n",
    "    df_kpis.to_excel(writer, sheet_name='KPIs_Monitoramento', index=False)\n",
    "    \n",
    "    # Aba 4: Evolu√ß√£o recomendada\n",
    "    evolucao = pd.DataFrame({\n",
    "        'Mes': ['M√™s 1', 'M√™s 2', 'M√™s 3', 'M√™s 4', 'M√™s 5', 'M√™s 6'],\n",
    "        'Meta_Atraso': [15.3, 12.0, 9.5, 7.5, 6.0, 5.0],\n",
    "        'Meta_Entregue': [10.8, 8.5, 6.5, 5.0, 4.0, 3.0],\n",
    "        'Meta_Cancelamento': [6.0, 5.0, 4.0, 3.5, 3.0, 2.5]\n",
    "    })\n",
    "    evolucao.to_excel(writer, sheet_name='Evolucao_Metas', index=False)\n",
    "    \n",
    "    # Aba 5: Respons√°veis\n",
    "    responsaveis = pd.DataFrame({\n",
    "        'Problema': ['ATRASO', 'ENTREGUE', 'CANCELAMENTO', 'ERRADO', 'DEFEITO'],\n",
    "        'Responsavel_Principal': ['Log√≠stica', 'TI', 'Vendas', 'Qualidade', 'P√≥s-Venda'],\n",
    "        'Responsavel_Secundario': ['Compras', 'Atendimento', 'Marketing', 'Warehouse', 'Fornecedores'],\n",
    "        'Prazo': ['3 meses', '2 meses', '2 meses', '4 meses', '3 meses']\n",
    "    })\n",
    "    responsaveis.to_excel(writer, sheet_name='Responsaveis', index=False)\n",
    "\n",
    "print(\"‚úÖ Dashboard salvo: dashboard_acoes.xlsx\")\n",
    "\n",
    "print(\"\"\"\n",
    "======================================================================\n",
    "üéØ RESUMO DAS DESCOBERTAS:\n",
    "======================================================================\n",
    "\n",
    "üèÜ TOP 3 PROBLEMAS (67% do esfor√ßo deve ser aqui):\n",
    "1. ATRASO (15.3%) ‚Üí Problema de LOG√çSTICA\n",
    "2. ENTREGUE (10.8%) ‚Üí Problema de SISTEMA\n",
    "3. CANCELAMENTO (6.0%) ‚Üí Problema de VENDAS\n",
    "\n",
    "üìä REGRA 80/20 APLICADA:\n",
    "‚Ä¢ Top 3 problemas = 32.1% de TODAS as reclama√ß√µes\n",
    "‚Ä¢ Focar nesses resolve 1/3 dos problemas dos clientes\n",
    "\n",
    "üí° INSIGHTS VALIOSOS:\n",
    "‚Ä¢ Clientes est√£o MUITO insatisfeitos com prazos\n",
    "‚Ä¢ Sistema de entrega tem falhas graves\n",
    "‚Ä¢ Processo de cancelamento precisa de aten√ß√£o\n",
    "\n",
    "üöÄ PR√ìXIMOS PASSOS:\n",
    "1. Apresente esses dados para a diretoria\n",
    "2. Crie squad para cada problema priorit√°rio\n",
    "3. Monitore redu√ß√£o mensalmente\n",
    "\n",
    "üéØ SEU BI AGORA TEM:\n",
    "‚Ä¢ Dados para tomar decis√µes baseadas em evid√™ncias\n",
    "‚Ä¢ Plano de a√ß√£o claro\n",
    "‚Ä¢ KPIs para medir sucesso\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a483e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
